{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self, eta=0.1, max_iter=100, n_categories=3, n_inputs=2):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.theta = np.random.randn(n_categories, n_inputs)\n",
    "        pass\n",
    "    \n",
    "    def get_score(self, X):\n",
    "        score = []\n",
    "        for cat in self.theta:\n",
    "            cat_score = []\n",
    "            for row in X:\n",
    "                row_score = cat.T.dot(row)\n",
    "                cat_score.append(row_score)\n",
    "                pass\n",
    "            score.append(cat_score)\n",
    "            pass\n",
    "        return np.array(score).T\n",
    "    \n",
    "    def get_softmax(self, X):\n",
    "        score = self.get_score(X)\n",
    "        softmax = []\n",
    "        for s in score:\n",
    "            p_softmax = []\n",
    "            cat_score_sum = np.sum([np.exp(cat_score) for cat_score in s], axis=0)\n",
    "            for cat_score in s:\n",
    "                cat_softmax = np.exp(cat_score) / cat_score_sum\n",
    "                p_softmax.append(cat_softmax)\n",
    "                pass\n",
    "            softmax.append(p_softmax)\n",
    "        return np.array(softmax)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        softmax = self.get_softmax(X)\n",
    "        probas = []\n",
    "        for proba in softmax:\n",
    "            probas.append(np.argmax(proba))\n",
    "            pass\n",
    "        return np.array(probas)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        softmax = self.get_softmax(X)\n",
    "        m = len(X)\n",
    "        self.losses = []\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i, cat_theta in enumerate(self.theta):\n",
    "                gradient = 1 / m * np.sum((softmax[:,i] - y[:,i]).dot(X))\n",
    "                self.theta[i] = cat_theta - self.eta * gradient\n",
    "                pass\n",
    "            pass\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data'][:, (2,3)]\n",
    "one = y == 0\n",
    "two = y == 1\n",
    "three = y == 2\n",
    "y = np.array([one,two,three]).astype(np.int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "n_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-25.91841892, -23.20595897],\n",
       "       [-14.21360952, -13.79264107],\n",
       "       [ 36.14933517,  36.82786354]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bla:\n",
    "    def __init__(self, eta=0.1, max_iter=100):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        pass\n",
    "\n",
    "    def fit(self, theta, X, y):\n",
    "        self.loss = 0\n",
    "        grad = np.zeros_like(theta)\n",
    "        dim, num_train = X.shape\n",
    "        \n",
    "        scores = theta.dot(X)\n",
    "        \n",
    "        scores -= np.max(scores)\n",
    "        scores_exp = np.exp(scores)\n",
    "        \n",
    "        scores_exp_sum = np.sum(scores_exp, axis=0)\n",
    "        \n",
    "        scores_exp_normalized = scores_exp / scores_exp_sum\n",
    "        \n",
    "        scores_exp_normalized[y] -= 1 # [K, N]\n",
    "        grad = scores_exp_normalized.dot(X.T)\n",
    "        grad /= num_train\n",
    "        grad += self.eta * theta\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def predict(self, theta, X):\n",
    "        self.loss = 0\n",
    "        grad = np.zeros_like(theta)\n",
    "        dim, num_train = X.shape\n",
    "        \n",
    "        scores = theta.dot(X)\n",
    "        \n",
    "        scores -= np.max(scores)\n",
    "        scores_exp = np.exp(scores)\n",
    "        \n",
    "        scores_exp_sum = np.sum(scores_exp, axis=0)\n",
    "        \n",
    "        scores_exp_normalized = scores_exp / scores_exp_sum\n",
    "        return np.argmax(scores_exp_normalized, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = Bla()\n",
    "theta = np.random.rand(3,2)\n",
    "for epoch in range(1000):\n",
    "    theta = bla.fit(theta, X.T, y)\n",
    "    print(precision_score(np.argmax(y, axis=1), bla.predict(theta, X.T), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.97215498,  1.0155697 ],\n",
       "       [-1.29015565, -0.4016979 ],\n",
       "       [-1.68199934, -0.6138718 ]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla.predict(theta, X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(np.argmax(y, axis=1), bla.predict(theta, X.T), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa59a212400>]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,100), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15567.241560984025, array([[-4.17629251, -1.33185124],\n",
       "        [-4.17629251, -1.33185124],\n",
       "        [ 4.17628872,  1.33185064]]))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla.fit(theta, X.T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo:\n",
    "    def foo(self, theta, X, y):\n",
    "        \"\"\"\n",
    "        theta[3,2] -> [inputs, categories]\n",
    "        X[2, 150] -> [inputs, samples]\n",
    "        y[150,] -> [samples]\n",
    "        \"\"\"\n",
    "        softmax_score = theta.dot(X)\n",
    "        print(F'softmax_score: {softmax_score.shape}')\n",
    "        \n",
    "        softmax_score_exp = np.exp(softmax_score)\n",
    "        print(F'softmax_score_exp: {softmax_score_exp.shape}')\n",
    "        \n",
    "        softmax_score_exp_sum = np.sum(softmax_score_exp, axis=1)\n",
    "        print(F'softmax_score_exp_sum: {softmax_score_exp_sum.shape}')\n",
    "        \n",
    "        softmax_score_exp_normalized = softmax_score_exp.T / softmax_score_exp_sum\n",
    "        print(F'softmax_score_exp_normalized: {softmax_score_exp_normalized.shape}')\n",
    "        \n",
    "        error = softmax_score_exp_normalized - y\n",
    "        print(F'error: {error.shape}')\n",
    "        \n",
    "        error_dotted = []\n",
    "        for category in error.T:\n",
    "            error_dotted.append(category.dot(X.T))\n",
    "        error_dotted = np.array(error_dotted)\n",
    "        # error_dotted = error.dot(X)\n",
    "        print(F'error_dotted: {error_dotted.shape}')\n",
    "        \n",
    "#        error_dotted_sum = np.sum(error_dotted, axis=0)\n",
    "#        print(F'error_dotted_sum: {error_dotted_sum.shape}')\n",
    "        \n",
    "        m = len(X)\n",
    "        eta = 0.1\n",
    "        gradient = 1 / m * error_dotted\n",
    "        print(F'gradient: {gradient.shape}')\n",
    "\n",
    "        theta -= eta * gradient\n",
    "        print(F'theta: {theta.shape}')\n",
    "\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones([len(X), 1]), X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 1. , 1.4, 0.2],\n",
       "       [1. , 1. , 1.4, 0.2],\n",
       "       [1. , 1. , 1.3, 0.2]])"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,2) and (4,150) not aligned: 2 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-658-ff3c085073e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-657-8b36cae5aa4d>\u001b[0m in \u001b[0;36mfoo\u001b[0;34m(self, theta, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msoftmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mF'softmax_score: {softmax_score.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,2) and (4,150) not aligned: 2 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "Foo().foo(np.random.rand(3,2), X.T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.rand(X.T.shape[0], y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = Foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,3) and (4,150) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-713-6a8f87c65f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-657-8b36cae5aa4d>\u001b[0m in \u001b[0;36mfoo\u001b[0;34m(self, theta, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msoftmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mF'softmax_score: {softmax_score.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,3) and (4,150) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    foo.foo(theta, X.T, y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55.23719568, 55.41546023, 75.54108095, 11.34688192],\n",
       "       [        nan,         nan,         nan,         nan],\n",
       "       [        nan,         nan,         nan,         nan]])"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
