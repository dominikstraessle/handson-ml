{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self, eta=0.1, max_iter=100, n_categories=3, n_inputs=2):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.theta = np.random.randn(n_categories, n_inputs)\n",
    "        pass\n",
    "    \n",
    "    def get_score(self, X):\n",
    "        score = []\n",
    "        for cat in self.theta:\n",
    "            cat_score = []\n",
    "            for row in X:\n",
    "                row_score = cat.T.dot(row)\n",
    "                cat_score.append(row_score)\n",
    "                pass\n",
    "            score.append(cat_score)\n",
    "            pass\n",
    "        return np.array(score).T\n",
    "    \n",
    "    def get_softmax(self, X):\n",
    "        score = self.get_score(X)\n",
    "        softmax = []\n",
    "        for s in score:\n",
    "            p_softmax = []\n",
    "            cat_score_sum = np.sum([np.exp(cat_score) for cat_score in s], axis=0)\n",
    "            for cat_score in s:\n",
    "                cat_softmax = np.exp(cat_score) / cat_score_sum\n",
    "                p_softmax.append(cat_softmax)\n",
    "                pass\n",
    "            softmax.append(p_softmax)\n",
    "        return np.array(softmax)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        softmax = self.get_softmax(X)\n",
    "        probas = []\n",
    "        for proba in softmax:\n",
    "            probas.append(np.argmax(proba))\n",
    "            pass\n",
    "        return np.array(probas)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        softmax = self.get_softmax(X)\n",
    "        m = len(X)\n",
    "        self.losses = []\n",
    "        for epoch in range(self.max_iter):\n",
    "            for i, cat_theta in enumerate(self.theta):\n",
    "                gradient = 1 / m * np.sum((softmax[:,i] - y[:,i]).dot(X))\n",
    "                self.theta[i] = cat_theta - self.eta * gradient\n",
    "                pass\n",
    "            pass\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data'][:, (2,3)]\n",
    "one = y == 0\n",
    "two = y == 1\n",
    "three = y == 2\n",
    "y = np.array([one,two,three]).astype(np.int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "n_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-25.91841892, -23.20595897],\n",
       "       [-14.21360952, -13.79264107],\n",
       "       [ 36.14933517,  36.82786354]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bla:\n",
    "    def __init__(self, eta=0.1, max_iter=100):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        pass\n",
    "\n",
    "    def fit(self, theta, X, y):\n",
    "        self.loss = 0\n",
    "        grad = np.zeros_like(theta)\n",
    "        dim, num_train = X.shape\n",
    "        \n",
    "        scores = theta.dot(X)\n",
    "        \n",
    "        scores -= np.max(scores)\n",
    "        scores_exp = np.exp(scores)\n",
    "        \n",
    "        scores_exp_sum = np.sum(scores_exp, axis=0)\n",
    "        \n",
    "        scores_exp_normalized = scores_exp / scores_exp_sum\n",
    "        \n",
    "        scores_exp_normalized[y] -= 1 # [K, N]\n",
    "        grad = scores_exp_normalized.dot(X.T)\n",
    "        grad /= num_train\n",
    "        grad += self.eta * theta\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def predict(self, theta, X):\n",
    "        self.loss = 0\n",
    "        grad = np.zeros_like(theta)\n",
    "        dim, num_train = X.shape\n",
    "        \n",
    "        scores = theta.dot(X)\n",
    "        \n",
    "        scores -= np.max(scores)\n",
    "        scores_exp = np.exp(scores)\n",
    "        \n",
    "        scores_exp_sum = np.sum(scores_exp, axis=0)\n",
    "        \n",
    "        scores_exp_normalized = scores_exp / scores_exp_sum\n",
    "        return np.argmax(scores_exp_normalized, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = Bla()\n",
    "theta = np.random.rand(3,2)\n",
    "for epoch in range(1000):\n",
    "    theta = bla.fit(theta, X.T, y)\n",
    "    print(precision_score(np.argmax(y, axis=1), bla.predict(theta, X.T), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.97215498,  1.0155697 ],\n",
       "       [-1.29015565, -0.4016979 ],\n",
       "       [-1.68199934, -0.6138718 ]])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla.predict(theta, X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(np.argmax(y, axis=1), bla.predict(theta, X.T), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa59a212400>]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,100), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15567.241560984025, array([[-4.17629251, -1.33185124],\n",
       "        [-4.17629251, -1.33185124],\n",
       "        [ 4.17628872,  1.33185064]]))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla.fit(theta, X.T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo:\n",
    "    def foo(self, theta, X, y):\n",
    "        \"\"\"\n",
    "        theta[3,2] -> [categories, inputs]\n",
    "        X[2, 150] -> [inputs, samples]\n",
    "        y[150, 3] -> [samples, categories]\n",
    "        \"\"\"\n",
    "        softmax_score = theta.dot(X)\n",
    "        print(F'softmax_score: {softmax_score.shape}')\n",
    "        \n",
    "        softmax_score_exp = np.exp(softmax_score)\n",
    "        print(F'softmax_score_exp: {softmax_score_exp.shape}')\n",
    "        \n",
    "        softmax_score_exp_sum = np.sum(softmax_score_exp, axis=1)\n",
    "        print(F'softmax_score_exp_sum: {softmax_score_exp_sum.shape}')\n",
    "        \n",
    "        softmax_score_exp_normalized = softmax_score_exp.T / softmax_score_exp_sum\n",
    "        print(F'softmax_score_exp_normalized: {softmax_score_exp_normalized.shape}')\n",
    "        return softmax_score_exp_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_score: (3, 150)\n",
      "softmax_score_exp: (3, 150)\n",
      "softmax_score_exp_sum: (3,)\n",
      "softmax_score_exp_normalized: (150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.0011362 , 0.00025038, 0.00098874],\n",
       "       [0.00117735, 0.00027878, 0.00107761],\n",
       "       [0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.00146302, 0.00037628, 0.00127091],\n",
       "       [0.00126657, 0.00029089, 0.00107376],\n",
       "       [0.00117735, 0.00027878, 0.00107761],\n",
       "       [0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.00107512, 0.00025319, 0.00103592],\n",
       "       [0.00117735, 0.00027878, 0.00107761],\n",
       "       [0.00119848, 0.00029416, 0.001125  ],\n",
       "       [0.00105617, 0.00023995, 0.00099228],\n",
       "       [0.00100129, 0.00020424, 0.0008721 ],\n",
       "       [0.00111617, 0.00023729, 0.00094709],\n",
       "       [0.00141189, 0.00033796, 0.0011661 ],\n",
       "       [0.00136254, 0.00030353, 0.00106993],\n",
       "       [0.00126657, 0.00029089, 0.00107376],\n",
       "       [0.00133599, 0.00034175, 0.00122174],\n",
       "       [0.0012893 , 0.00030694, 0.00112098],\n",
       "       [0.00121999, 0.00031039, 0.00117447],\n",
       "       [0.00141189, 0.00033796, 0.0011661 ],\n",
       "       [0.00107716, 0.00021312, 0.00086899],\n",
       "       [0.00160213, 0.0004143 , 0.00132206],\n",
       "       [0.00126417, 0.00034559, 0.00128003],\n",
       "       [0.00119848, 0.00029416, 0.001125  ],\n",
       "       [0.00143723, 0.00035661, 0.00121738],\n",
       "       [0.00117735, 0.00027878, 0.00107761],\n",
       "       [0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.00119848, 0.00029416, 0.001125  ],\n",
       "       [0.00119848, 0.00029416, 0.001125  ],\n",
       "       [0.00141189, 0.00033796, 0.0011661 ],\n",
       "       [0.00107512, 0.00025319, 0.00103592],\n",
       "       [0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.00107512, 0.00025319, 0.00103592],\n",
       "       [0.00111617, 0.00023729, 0.00094709],\n",
       "       [0.0011362 , 0.00025038, 0.00098874],\n",
       "       [0.00107512, 0.00025319, 0.00103592],\n",
       "       [0.0011362 , 0.00025038, 0.00098874],\n",
       "       [0.00117735, 0.00027878, 0.00107761],\n",
       "       [0.00124424, 0.00027568, 0.00102853],\n",
       "       [0.00124424, 0.00027568, 0.00102853],\n",
       "       [0.0011362 , 0.00025038, 0.00098874],\n",
       "       [0.00172353, 0.00043231, 0.00131734],\n",
       "       [0.001516  , 0.00041896, 0.00138514],\n",
       "       [0.00126657, 0.00029089, 0.00107376],\n",
       "       [0.00119848, 0.00029416, 0.001125  ],\n",
       "       [0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.00117735, 0.00027878, 0.00107761],\n",
       "       [0.00115659, 0.0002642 , 0.00103222],\n",
       "       [0.00618688, 0.00493589, 0.00685769],\n",
       "       [0.00653837, 0.00488105, 0.00654538],\n",
       "       [0.00702051, 0.00605095, 0.00777489],\n",
       "       [0.00498827, 0.00307802, 0.00487767],\n",
       "       [0.00665571, 0.0051504 , 0.00683321],\n",
       "       [0.00545223, 0.00402632, 0.00604869],\n",
       "       [0.00741936, 0.00598372, 0.00742081],\n",
       "       [0.00335377, 0.00158333, 0.00320607],\n",
       "       [0.00555008, 0.0042485 , 0.00631467],\n",
       "       [0.00536627, 0.00321178, 0.00486026],\n",
       "       [0.00347523, 0.00176289, 0.00349424],\n",
       "       [0.00619861, 0.00415462, 0.00575262],\n",
       "       [0.00379846, 0.00230602, 0.00433313],\n",
       "       [0.00618688, 0.00493589, 0.00685769],\n",
       "       [0.00464569, 0.00248291, 0.00410632],\n",
       "       [0.00586539, 0.0042013 , 0.0060271 ],\n",
       "       [0.00653837, 0.00488105, 0.00654538],\n",
       "       [0.00386663, 0.00243327, 0.00452367],\n",
       "       [0.00653837, 0.00488105, 0.00654538],\n",
       "       [0.0040863 , 0.00240624, 0.00431766],\n",
       "       [0.00905704, 0.00765427, 0.0083833 ],\n",
       "       [0.00498827, 0.00307802, 0.00487767],\n",
       "       [0.00702051, 0.00605095, 0.00777489],\n",
       "       [0.00515913, 0.00407156, 0.00633729],\n",
       "       [0.00526168, 0.00361621, 0.00554985],\n",
       "       [0.00586539, 0.0042013 , 0.0060271 ],\n",
       "       [0.00629791, 0.00520827, 0.00715925],\n",
       "       [0.00857015, 0.00774027, 0.0087833 ],\n",
       "       [0.00653837, 0.00488105, 0.00654538],\n",
       "       [0.00347523, 0.00176289, 0.00349424],\n",
       "       [0.00401426, 0.0022804 , 0.00413579],\n",
       "       [0.00360108, 0.00196282, 0.00380831],\n",
       "       [0.00447484, 0.00264936, 0.00449144],\n",
       "       [0.00796647, 0.0074179 , 0.00881476],\n",
       "       [0.00653837, 0.00488105, 0.00654538],\n",
       "       [0.00716006, 0.00537423, 0.00680882],\n",
       "       [0.00677515, 0.00543461, 0.00713369],\n",
       "       [0.00535611, 0.00381576, 0.0057939 ],\n",
       "       [0.00507779, 0.00324787, 0.00509216],\n",
       "       [0.00498827, 0.00307802, 0.00487767],\n",
       "       [0.00489105, 0.0034656 , 0.00556973],\n",
       "       [0.0060778 , 0.00467776, 0.00656883],\n",
       "       [0.00455515, 0.00279556, 0.00468895],\n",
       "       [0.00335377, 0.00158333, 0.00320607],\n",
       "       [0.00516892, 0.00342709, 0.00531608],\n",
       "       [0.00472011, 0.0031126 , 0.0051104 ],\n",
       "       [0.00516892, 0.00342709, 0.00531608],\n",
       "       [0.00526168, 0.00361621, 0.00554985],\n",
       "       [0.00348182, 0.00148385, 0.00293117],\n",
       "       [0.00507779, 0.00324787, 0.00509216],\n",
       "       [0.0211747 , 0.02860563, 0.01852042],\n",
       "       [0.01046185, 0.00990122, 0.00992251],\n",
       "       [0.01446447, 0.01844648, 0.01515003],\n",
       "       [0.01044204, 0.01176314, 0.0118286 ],\n",
       "       [0.01556056, 0.01924814, 0.01509595],\n",
       "       [0.01638238, 0.02686616, 0.02047585],\n",
       "       [0.00784087, 0.00591723, 0.00708286],\n",
       "       [0.0118266 , 0.01713229, 0.01598681],\n",
       "       [0.0108202 , 0.01309719, 0.01289178],\n",
       "       [0.02155471, 0.03018415, 0.01933484],\n",
       "       [0.01145661, 0.01090163, 0.01032187],\n",
       "       [0.01084072, 0.01102411, 0.01081436],\n",
       "       [0.0134711 , 0.01488003, 0.01275423],\n",
       "       [0.01125463, 0.01033151, 0.00988709],\n",
       "       [0.01647577, 0.01602145, 0.01208665],\n",
       "       [0.01559007, 0.01620146, 0.01266335],\n",
       "       [0.01025795, 0.01114797, 0.01133036],\n",
       "       [0.01826204, 0.03121301, 0.02223661],\n",
       "       [0.02072271, 0.03826425, 0.02521071],\n",
       "       [0.00714651, 0.00638485, 0.00811678],\n",
       "       [0.0167397 , 0.02008463, 0.01504207],\n",
       "       [0.01105621, 0.00979121, 0.00947063],\n",
       "       [0.0152284 , 0.02574722, 0.02054919],\n",
       "       [0.00921958, 0.00807665, 0.00875195],\n",
       "       [0.01395895, 0.01656756, 0.01390061],\n",
       "       [0.01121205, 0.01458253, 0.01405052],\n",
       "       [0.00905704, 0.00765427, 0.0083833 ],\n",
       "       [0.00921958, 0.00807665, 0.00875195],\n",
       "       [0.01371286, 0.01570114, 0.01331509],\n",
       "       [0.00902278, 0.01080371, 0.01191349],\n",
       "       [0.01249849, 0.01694194, 0.01525876],\n",
       "       [0.01443709, 0.02191533, 0.01806032],\n",
       "       [0.01501673, 0.01728756, 0.013851  ],\n",
       "       [0.00727476, 0.00673718, 0.00847371],\n",
       "       [0.00726099, 0.0080041 , 0.01010149],\n",
       "       [0.01797411, 0.02489853, 0.01786762],\n",
       "       [0.0180082 , 0.02095748, 0.01498839],\n",
       "       [0.01025795, 0.01114797, 0.01133036],\n",
       "       [0.00905704, 0.00765427, 0.0083833 ],\n",
       "       [0.0132336 , 0.01410186, 0.012217  ],\n",
       "       [0.0180082 , 0.02095748, 0.01498839],\n",
       "       [0.01504521, 0.01455122, 0.01161901],\n",
       "       [0.01046185, 0.00990122, 0.00992251],\n",
       "       [0.01734593, 0.02236242, 0.01639409],\n",
       "       [0.0200744 , 0.02434833, 0.01627727],\n",
       "       [0.01531522, 0.01535418, 0.01212995],\n",
       "       [0.01027741, 0.00938342, 0.00950455],\n",
       "       [0.01166221, 0.0115032 , 0.01077576],\n",
       "       [0.01586986, 0.01709549, 0.01322021],\n",
       "       [0.00955347, 0.00899262, 0.0095386 ]])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Foo().foo(np.random.rand(3,2), X.T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
